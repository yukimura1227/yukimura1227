## 🎯 概要

**課題**: [コード実行基盤の障害が多く、特に変更失敗率が6割を超えていた]
**期間**: [2024-05 〜 2024-08]
**役割**: [テックリード・アーキテクト]

## ☝️ 背景

運営しているWebサービスに、ユーザーがsubmitした、任意のソースコードを実行する、コード実行基盤が10年近く運営されていました。
機能として、完成度が高かったため、改修をいれる頻度は高くなく、かつ、有識者も一人しかいないために、修正の都度障害が発生するような状況でした。
そのコード実行基盤を、他社のサービスに組み込みたいという要望があり、品質的にそのまま提供することはできない旨を伝え、製造請負開発として受託開発を行い、アーキテクチャの刷新による、品質向上を行いました。

## 📊 課題の詳細
### 現状分析
- 改善必須の課題
	- [課題1]:  変更失敗率が6割程度(年に3回程度変更が入るうち、2回程度は、大小障害が発生している)
	- [課題2]:  監視が弱く、直接的な障害検知ができておらず、該当サービスを利用しているサービスの監視によって障害を検知している
- 改善必須ではない課題
	- 課題3: サーバー(EC2)がIasC管理されておらず、サーバーのOS・ミドルのupgradeも困難
	- 課題4: 性能担保のために、過剰な大きさのインスタンスを利用しており、高コスト
- [影響範囲]: どの範囲に影響していたか

### 解決すべき目標
- [目標1]:  変更失敗率99%
- [目標2]:  異常発生時に直接的に障害が検知できるように監視を強化する
- 目標3: リアーキテクチャ後のすべてのインフラをIasCで管理する
- 目標4:  インフラリソース効率を最大化し、ベストエフォートでコスト圧縮する

## 🛠️ ソリューション・アプローチ
###  リアーキテクチャ前後比較

- Webアプリケーション部分(APIのみ、画面はありません。)
	- EC2 -> ECS
		- Intel CPU -> ARM
		- ContainerInsightによる各種監視項目の収集を追加
	- Rails(4系) -> Rails(7系)
	- API仕様書 OpenAPI -> OpenAPI
	- データの永続化 MySQL -> Redis(長期的な永続化は不要と判断)
- 実行基盤（実際にコンパイル＆実行を行う部分）
	- Rubyによる自前のdaemonプロセス -> 踏襲
	- 自動テスト無し -> Ruby標準のmini test
	- すべての言語に対応した巨大なdocker image -> 全言語別々のdocker image
	- EC2 -> EC2
		- ただし、改善後はEC2ImageBuilderを利用したイミュータブルインフラストラクチャの構成に改善
		- Intel CPU -> ARM
		- 巨大なEC2で3プロセス並列処理 -> EC2は最小限に1プロセスでスケールアウトの単位を最小化
		- CloudWatchAgentによる各種監視項目の収集を追加
		- ubuntu20 -> ubuntu20(OS upgradeを、リアーキテクチャのタイミングではできなかった)
	- Gracefull Shutdown非対応 -> Gracefull Shutdownに対応
- キューイングミドルウェア
	- RabbitMQ -> Redis
-  監視基盤
	-  Zabbix -> AWS GrafanaとCloudWatchMetrics

## 🎉 成果・効果

### 目標に対する成果・効果

- **[指標1]**: 変更失敗率は、0%(2025/08/04時点 10回リリースを実施)
- **[指標2]**:  2025/08/04時点  2回の予兆検知があり、障害になる前に運用対処を行うことができた
- **[指標3]**:  リアーキテクチャ後のすべてのインフラは、terraformで実現している。
	- また、ローカル開発環境向けに、Webはdocker compose、実行基盤は、limaを利用したVMでローカルで検証できるようにしている。
- **[指標4]**:  $1 = 150円で換算すると、年間で約900万のコスト圧縮を達成している。

### その他の成果・効果

極力、リリース手順を自動化したことで、これまで一人しかできなかったリリース作業を、複数人（2025/08/04の実績では、5名)でリリースできるようになりました。
また、何かあった場合の切り戻し手順を整備し、変更失敗の障害時は、迅速に切り戻しができるようにしました。
また、ステージング環境を構築したうえで、外形監視を行うためのツールを作成したため、基本的にはステージング環境の外形監視によって、本番環境に反映する前に、問題に気づけるようにしています。
負荷テスト（限界負荷テスト含む）、長期安定稼働確認テスト、インフラ異常系確認（FailOverのケースなど）を行い、安定性を担保しています。

## 🚧 課題・学習
### 直面した困難
- [困難1]:  性能が向上しすぎたため、当初想定していなかった範囲の検証を行うことになった
- [困難2]:  大幅なコスト圧縮見込みが信じてもらえなかったため、根拠を出すのに、追加の作り込みを行う必要性が生じた

### 学んだこと(TODO)
- **技術面**: 新しく習得した知識・スキル
- **マネジメント面**: リーダーシップやチーム運営の学び
- **次回への活かし方**: 今後類似プロジェクトでの改善点


## 📈 波及効果(TODO)
### 組織への影響(TODO)
- **採用**: 技術力アピールに活用
- **教育**: 新人研修での事例活用
- **標準化**: 他プロジェクトへの展開

### 継続的改善(TODO)
- **現在の状況**: 導入後の運用状況
- **今後の計画**: さらなる改善予定